{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_RTtO5qAJoY"
      },
      "outputs": [],
      "source": [
        "!apt install ffmpeg\n",
        "!pip install spleeter\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install SpeechRecognition\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import csv\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKkH5l--XBMo",
        "outputId": "6ce3bbc8-cd54-49f1-c7a8-2bae941fecd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR:spleeter:An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/vocals.wav-o: No such file or directory\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!spleeter separate /content/vocals.wav-o output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tgezldew-Dl",
        "outputId": "15dede29-04df-4f29-88d6-5e9dae7e9066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "Estimated Word Timestamps:\n",
            "Word: तेरे | Start Time: 0.0 ms | End Time: 4176.466666666666 ms\n",
            "Word: नाल | Start Time: 4176.466666666666 ms | End Time: 8352.933333333332 ms\n",
            "Word: दिया | Start Time: 8352.933333333332 ms | End Time: 12529.399999999998 ms\n",
            "Word: मेनू | Start Time: 12529.399999999998 ms | End Time: 16705.866666666665 ms\n",
            "Word: जान | Start Time: 16705.866666666665 ms | End Time: 20882.333333333332 ms\n",
            "Word: दिया | Start Time: 20882.333333333332 ms | End Time: 25058.799999999996 ms\n",
            "Word: तेरे | Start Time: 25058.799999999996 ms | End Time: 29235.266666666663 ms\n",
            "Word: मेरे | Start Time: 29235.266666666663 ms | End Time: 33411.73333333333 ms\n",
            "Word: नैनो | Start Time: 33411.73333333333 ms | End Time: 37588.2 ms\n",
            "Word: पहचान | Start Time: 37588.2 ms | End Time: 41764.666666666664 ms\n",
            "Word: दिया | Start Time: 41764.666666666664 ms | End Time: 45941.13333333333 ms\n",
            "Word: तू | Start Time: 45941.13333333333 ms | End Time: 50117.59999999999 ms\n",
            "Word: सुना | Start Time: 50117.59999999999 ms | End Time: 54294.06666666666 ms\n",
            "Word: ता | Start Time: 54294.06666666666 ms | End Time: 58470.533333333326 ms\n",
            "Word: सही | Start Time: 58470.533333333326 ms | End Time: 62646.99999999999 ms\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "# Load the audio file (replace 'audio_file_path' with the actual path)\n",
        "audio_file_path = '/vocals.wav'\n",
        "audio = AudioSegment.from_file(audio_file_path, format=\"wav\")\n",
        "\n",
        "# Perform speech recognition using the SpeechRecognition library\n",
        "recognizer = sr.Recognizer()\n",
        "with sr.AudioFile(audio_file_path) as source:\n",
        "    audio_data = recognizer.record(source)\n",
        "\n",
        "text = recognizer.recognize_google(audio_data, language='hi-IN')\n",
        "\n",
        "# Estimate timestamps based on word count\n",
        "words = text.split()\n",
        "\n",
        "num_words=len(words)\n",
        "print(num_words)\n",
        "\n",
        "word_duration = len(audio) / len(words)\n",
        "\n",
        "timestamps = []\n",
        "for i, word in enumerate(words):\n",
        "    start_time = i * word_duration\n",
        "    end_time = (i + 1) * word_duration\n",
        "    timestamps.append((word, start_time, end_time))\n",
        "\n",
        "# Print estimated timestamps\n",
        "print(\"Estimated Word Timestamps:\")\n",
        "for word, start, end in timestamps:\n",
        "    print(f\"Word: {word} | Start Time: {start} ms | End Time: {end} ms\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgja5qeO6C_v",
        "outputId": "8023e3d8-252f-4134-a8ea-47a354399588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVj8Jq0rmLnk"
      },
      "outputs": [],
      "source": [
        "# Load the audio file (replace 'audio_file_path' with the actual path)\n",
        "audio_file_path = '/content/drive/MyDrive/Project Sample audio/Aj Jane.wav'\n",
        "audio = AudioSegment.from_file(audio_file_path, format=\"wav\")\n",
        "\n",
        "# Perform speech recognition using the SpeechRecognition library\n",
        "recognizer = sr.Recognizer()\n",
        "with sr.AudioFile(audio_file_path) as source:\n",
        "    audio_data = recognizer.record(source)\n",
        "\n",
        "text = recognizer.recognize_google(audio_data, language='hi-IN')\n",
        "\n",
        "# Split the recognized text into words\n",
        "words = text.split()\n",
        "\n",
        "num_words=len(words)\n",
        "\n",
        "# Calculate word timestamps as before\n",
        "word_duration = len(audio) / len(words)\n",
        "timestamps = []\n",
        "for i, word in enumerate(words):\n",
        "    start_time = i * word_duration\n",
        "    end_time = (i + 1) * word_duration\n",
        "    timestamps.append((word, start_time, end_time))\n",
        "\n",
        "# Calculate the fundamental frequency (pitch) of each word\n",
        "word_pitch = {}\n",
        "for word, start, end in timestamps:\n",
        "    word_audio = audio[int(start):int(end)]\n",
        "    y, sr = librosa.load(word_audio.export(format=\"wav\"), sr=None)\n",
        "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
        "    # Extract the pitch (frequency) information\n",
        "    pitch = np.mean(pitches)\n",
        "    word_pitch[word] = pitch\n",
        "\n",
        "# Convert pitch (frequency) into corresponding musical notes\n",
        "def frequency_to_note_name(frequency):\n",
        "    if frequency <= 0:\n",
        "        return \"Unknown\"\n",
        "    n = 12 * (np.log2(frequency / 440)) + 49\n",
        "    note_names = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
        "    octave = int(n // 12)\n",
        "    note = int(n % 12)\n",
        "    return f\"{note_names[note]}{octave}\"\n",
        "\n",
        "# Print estimated timestamps, exact frequency, and corresponding musical notes\n",
        "print(\"Estimated Word Timestamps, Frequencies, and Musical Notes:\")\n",
        "for word, start, end in timestamps:\n",
        "    pitch = word_pitch[word]\n",
        "    note = frequency_to_note_name(pitch)\n",
        "    print(f\"Word: {word} | Start Time: {start} ms | End Time: {end} ms | Pitch (Frequency): {pitch:.2f} Hz | Note: {note}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA-NTG6HDVaR"
      },
      "outputs": [],
      "source": [
        "#headers contains the names of the columns\n",
        "'''Pid-unique id to recognise each element\n",
        "   Words-contains corresponding words\n",
        "   s_time- starting time\n",
        "   e_time- ending time\n",
        "   time- e_time-s_time\n",
        "   frequency- avg tonal frequency of the words\n",
        "   freq_diff- frequency diff\n",
        "'''\n",
        "headers=[\"Pid\",\"Words\",\"s_time\",\"e_time\",\"time\",\"frequency\",\"freq_diff\"]\n",
        "with open('names.csv','w')as csv_file:\n",
        "    song_csv=csv.writer(csv_file,delimiter='-')\n",
        "    song_csv.writerow(headers)\n",
        "    for i in range(0,num_words):\n",
        "\n",
        "      song_csv.writerows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
